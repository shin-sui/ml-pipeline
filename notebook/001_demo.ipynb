{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/suizushinsaku/.local/share/uv/python/cpython-3.12.9-macos-x86_64-none/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/suizushinsaku/.local/share/uv/python/cpython-3.12.9-macos-x86_64-none/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/suizushinsaku/.local/share/uv/python/cpython-3.12.9-macos-x86_64-none/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/p2/yr613j_13_q5bgk1ptptj4nw0000gn/T/ipykernel_10155/3616409008.py\", line 7, in <module>\n",
      "    import torch\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import polars as pl\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertJapaneseTokenizer, BertModel\n",
    "import pytorch_lightning as L\n",
    "\n",
    "# 日本語の事前学習モデル\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pl.read_csv(\"../data/processed/train.csv\")\n",
    "df_test = pl.read_csv(\"../data/processed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassificationMultiLabel(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, modl_name, num_labels):\n",
    "    super() .__init__()\n",
    "    # BertModelのロード\n",
    "    self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "    # 線形変換を初期化しておく\n",
    "    self.linear = torch.nn.Linear(\n",
    "        self.bert.config.hidden_size, num_labels\n",
    "    )\n",
    "\n",
    "  def forward(\n",
    "      self,\n",
    "      input_ids=None,\n",
    "      attention_mask=None,\n",
    "      token_type_ids=None,\n",
    "      labels=None     \n",
    "  ):\n",
    "    # データを入力しBERTの最終層の出力を得る\n",
    "    bert_output = self.bert(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids)\n",
    "    last_hidden_state = bert_output.last_hidden_state\n",
    "\n",
    "    # [PAD]以外のトークンで隠れ状態の平均をとる\n",
    "    averaged_hedden_state = \\\n",
    "      (last_hidden_state*attention_mask.unsqueeze(-1)).sum(1) \\\n",
    "      / attention_mask.sum(1, keepdim=True)\n",
    "\n",
    "    # 線形変換\n",
    "    scores = self.linear(averaged_hedden_state)\n",
    "\n",
    "    # 出力の形式を整える\n",
    "    output = {'logits': scores}\n",
    "\n",
    "    # labelsが入力に含まれていたら、損失を計算し出力する\n",
    "    if labels is not None:\n",
    "      loss = torch.nn.BCEWithLogitsLoss() (scores, labels.float())\n",
    "      output['loss'] = loss\n",
    "\n",
    "    # 属性でアクセスできるようにする\n",
    "    output = type('bert_output', (object,), output)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "class BertForSequenceClassificationMultiLabel_pl(L.LightningModule):\n",
    "\n",
    "  def __init__(self, model_name, num_labels, lr):\n",
    "    super() .__init__()\n",
    "    self.save_hyperparameters()\n",
    "    self.bert_scml = BertForSequenceClassificationMultiLabel(\n",
    "        model_name, num_labels=num_labels\n",
    "    )\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    output = self.bert_scml(**batch)\n",
    "    loss = output.loss\n",
    "    self.log('train_loss', loss)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    output = self.bert_scml(**batch)\n",
    "    val_loss = output.loss\n",
    "    self.log('val_loss', val_loss)\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    labels = batch.pop('labels')\n",
    "    output = self.bert_scml(**batch)\n",
    "    scores = output.logits\n",
    "    labels_predicted = ( scores > 0 ).int()\n",
    "    num_correct = ( labels_predicted == labels ).all(-1).sum().item()\n",
    "    accuracy = num_correct/scores.size(0)\n",
    "    self.log('accuracy', accuracy)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "checkpoint = L.callbacks.ModelCheckpoint(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min',\n",
    "    save_top_k=1,\n",
    "    save_weights_only=True,\n",
    "    dirpath = 'model/',\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    # gpus=1,\n",
    "    max_epochs=5,\n",
    "    callbacks = [checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "G06V30_l_train = []\n",
    "G06V30_l_test = []\n",
    "\n",
    "for fi_l in df_train[\"FI\"]:\n",
    "    if \"G06V30\" in fi_l:\n",
    "        encode = 1\n",
    "    else:\n",
    "        encode = 0\n",
    "    G06V30_l_train.append(encode)\n",
    "\n",
    "for fi_l in df_test[\"FI\"]:\n",
    "    if \"G06V30\" in fi_l:\n",
    "        encode = 1\n",
    "    else:\n",
    "        encode = 0\n",
    "    G06V30_l_test.append(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "# 各データの形式を整える\n",
    "max_length = 256\n",
    "train_dataset_for_loader = []\n",
    "test_dataset_for_loader = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "  text = df_train[\"summary\"][i]\n",
    "  labels = [G06V30_l_train[i]]\n",
    "  encoding = tokenizer(\n",
    "      text,\n",
    "      max_length=max_length,\n",
    "      padding='max_length',\n",
    "      truncation=True\n",
    "  )\n",
    "  encoding['labels'] = labels\n",
    "  encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
    "  train_dataset_for_loader.append(encoding)\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "  text = df_test[\"summary\"][i]\n",
    "  labels = [G06V30_l_test[i]]\n",
    "  encoding = tokenizer(\n",
    "      text,\n",
    "      max_length=max_length,\n",
    "      padding='max_length',\n",
    "      truncation=True\n",
    "  )\n",
    "  encoding['labels'] = labels\n",
    "  encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
    "  test_dataset_for_loader.append(encoding)\n",
    "\n",
    "# データセットの分割\n",
    "random.shuffle(train_dataset_for_loader)\n",
    "n = len(train_dataset_for_loader)\n",
    "n_train = int(0.7*n)\n",
    "dataset_train = train_dataset_for_loader[:n_train]  # 学習データ\n",
    "dataset_val = train_dataset_for_loader[n_train:]  # 検証データ\n",
    "dataset_test = test_dataset_for_loader # テストデータ\n",
    "\n",
    "# データセットからデータローダを作成\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, batch_size=32, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=256)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type                                    | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | bert_scml | BertForSequenceClassificationMultiLabel | 110 M  | train\n",
      "------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.472   Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "228       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 43/43 [14:30<00:00,  0.05it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 43/43 [14:30<00:00,  0.05it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /Users/suizushinsaku/develop/patent/notebook/model/epoch=4-step=215.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/suizushinsaku/develop/patent/notebook/model/epoch=4-step=215.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suizushinsaku/develop/patent/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:39<00:00,  0.03it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        accuracy            0.9951691031455994\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassificationMultiLabel_pl(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1,   #対象とするFI数\n",
    "    lr=1e-5\n",
    ")\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "test = trainer.test(dataloaders=dataloader_test)\n",
    "print(f'Accuracy: {test[0] [\"accuracy\"]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "入力 : テキストシーケンス方式であっても、文字認識結果として得られた文字が、認識対象における文字列画像のどの位置にあるかを把握するまでの時間を低減する。文字列を表す文字列画像から文字を認識する文字列画像認識において当該文字列画像に記載された文字列、および前記文字列画像における1文字以上の文字が含まれる部分文字列の位置を学習する学習モデル学習システムであって、前記部分文字列が2つ以上含まれる1行の文字列が書かれた文字列画像、前記文字列画像上に書かれている文字列及び前記文字列画像における各部分文字列の始端・終端位置情報を用いて学習することで学習モデルを生成する学習部を備える。\n",
      "出力 : [1]\n"
     ]
    }
   ],
   "source": [
    "# text_list = []\n",
    "# for i in range(len(df_test[:5])):\n",
    "#     text = df_test[\"summary\"][i]\n",
    "#     text_list.append(text)\n",
    "\n",
    "# # モデルのロード\n",
    "best_model_path = checkpoint.best_model_path\n",
    "model = BertForSequenceClassificationMultiLabel_pl.load_from_checkpoint(best_model_path)\n",
    "bert_scml = model.bert_scml\n",
    "\n",
    "text_list = [df_test.filter(pl.col(\"FI\").str.contains(\"G06V30\"))[\"summary\"][1]]\n",
    "# データの符号化\n",
    "encoding = tokenizer(\n",
    "    text_list,\n",
    "    padding = 'longest',\n",
    "    return_tensors = 'pt'\n",
    ")\n",
    "encoding = { k: v for k, v in encoding.items() }\n",
    "\n",
    "# BERTへデータを入力し分類スコアを得る\n",
    "with torch.no_grad():\n",
    "  output = bert_scml(**encoding)\n",
    "scores = output.logits\n",
    "labels_predicted = ( scores > 0).int().tolist()\n",
    "\n",
    "# 結果を表示\n",
    "for text, label in zip(text_list, labels_predicted):\n",
    "  print('--')\n",
    "  print(f'入力 : {text}')\n",
    "  print(f'出力 : {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4610]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'テキストシーケンス方式であっても、文字認識結果として得られた文字が、認識対象における文字列画像のどの位置にあるかを把握するまでの時間を低減する。文字列を表す文字列画像から文字を認識する文字列画像認識において当該文字列画像に記載された文字列、および前記文字列画像における1文字以上の文字が含まれる部分文字列の位置を学習する学習モデル学習システムであって、前記部分文字列が2つ以上含まれる1行の文字列が書かれた文字列画像、前記文字列画像上に書かれている文字列及び前記文字列画像における各部分文字列の始端・終端位置情報を用いて学習することで学習モデルを生成する学習部を備える。'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b5764d990ca041aec3db646251fce252e662ccbdb87b1246075793e7e44213d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
